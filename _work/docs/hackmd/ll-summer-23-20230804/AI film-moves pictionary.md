# AI film-moves pictionary 

![alt text](https://files.slack.com/files-pri/T0HTW3H0V-F05JT263QRK/jgtc_360.gif?pub_secret=dc019edc82)

Guessing is fun - so it has that going for it. But standard guessing games don't really engage guessers as active learners/problem-solvers/creative thinkers. How can we create creator/guesser relationship where the guessers are practicing their "know-how" or "know-why" rather than "knowing that"?

**AI film-moves pictionary:** Instead of simply presenting a movie still and asking students to identify the movie, what if we designed a pictionary remix that uses AI to get students to recognize and translate specific "film-moves" across real and AI-generated stills? (while simultaniously getting students to practice prompting in AI and evaluate it's database/interpretation)


basic structure is:

Part 1: identifying the key “film-moves” in a given set of stills

- we supply pre-identified shots from a film or set of films that students are studying (print them out, project them, show them on screen)
- using cards, students identify the “moves” used in each shot (shot length, lighting, etc)

Part 2: replicating a set of “moves” to create an entirely new image in midjourney 

- creator takes on set of moves identified for one of the shots and uses those moves as prompts for midjourney to construct an entirely new image (completely different content, same moves) and the guessers are trying to figure out which shot from Part 1 they are pulling the moves from (match the set of moves with AI-generated image to set of moves of the film shot)

![alt text](https://files.slack.com/files-pri/T0HTW3H0V-F05K8KV60DP/film-pictionary-5.jpg?pub_secret=50f4ed6857)


### Key moves 

- Creation/guesser roles
- Voice of God / Narrator 
- Group discussion/deliberation
- Supersource (for part 2)
    - AI-generated image
    - Narrator/voice of god
    - main table
    - green screen keyed on main table overhead
- Chroma key 
- Flying key 

### Set-up 

- print-out four movie stills 
- cards
- green paper main table & overhead 
- midjourney on main computer


### Roles

part 1:
- voice of god/narrator
- host
- contestants
- prompter/recorder

part 2:
- prompter (using midjourney)
- host
- guesser (on greenscreen)
- audience (at tablescape)
- narrator/voice of god 

### OG images:


the french connection (1971)
![alt text](https://files.slack.com/files-pri/T0HTW3H0V-F05H6NZB64X/screen_shot_2023-07-18_at_2.36.11_pm.png?pub_secret=d29699572d)

the conformist (1970)
![alt text](https://files.slack.com/files-pri/T0HTW3H0V-F05HPNGAD4L/screen_shot_2023-07-18_at_2.36.21_pm.png?pub_secret=1aa0fc3577)


the godfather (1972)
![alt text](https://files.slack.com/files-pri/T0HTW3H0V-F05HJBLUPEZ/screen_shot_2023-07-18_at_2.36.28_pm.png?pub_secret=3f6ce9ad13)

the last tango (1972)
![alt text](https://files.slack.com/files-pri/T0HTW3H0V-F05H6P1MJRM/last-tango-1.webp?pub_secret=def5724052)


### AI-generated images

the french connection (1971)
![alt text](https://files.slack.com/files-pri/T0HTW3H0V-F05HQ6THGJ0/kewl3.png?pub_secret=b1c8ec520b)

the conformist (1970)
![alt text](https://files.slack.com/files-pri/T0HTW3H0V-F05HF3RNJB0/kewl2.png?pub_secret=bb82dde81e)

the godfather (1972)
![alt text](https://files.slack.com/files-pri/T0HTW3H0V-F05HF3SF60N/kewl1.png?pub_secret=6a0cf0a5b2)

the last tango (1972)
![alt text](https://files.slack.com/files-pri/T0HTW3H0V-F05H77AEXGF/kewl4.png?pub_secret=17508b9b0d)


### DOCUMENTATION

<iframe width="560" height="315" src="https://www.youtube.com/embed/wvTRWsL08oU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>


# notes post-activity 

* Jessi's framing questions: 
    * how might you apply this to courses we teach?
    * how could we use this in a workshop?
        * today was less about the content of film, and more on the mechanics and flow of this activity. 
        * Think of how it could be applied. 

CC's response: 
* interesting to see when you make a composition abtract, how you can make it back to the composition. 
    * an interesting way to examine the flow of: 
        * content to 
        * abstraction to 
        * composition 
* any case where you have to divorce content from composition, this is a strong activity 

Jacob: 

* it was interesting seeing how an AI takes framing choices from film (storytelling, not just composition) and removing the story to solely create an image. 
    * "we make meaning because of how we frame it, when creating a film"
        * this removes meaning, and forces us to focus on pure composition 

Kevin: 

* it obviously teaches you about prompting on midjourney and analyzing AI, which will become an increasingly important skill 
    * however, AI provides a look into a pool of aesthetic content available online, as well as our connotations about that content. 
        * ex. "we describe certain frames as gloomy or bleak. and ai can translate those connotations into images, that create an interesting feedback loop."
        * JESSI response: 
            * similarly, "prescriptive" versus "descriptive" feedback is something to keep in mind when analyzing/critiquing AI images. 
                * AI is less nuanced. 


CC: 

* an interesting add to this activity would be to take a still from a highly stylized film (such as neon demon) to compare the midjourney recreation versus the entire scene. 
    * in what ways does context/movements change our understanding or connotations?

MW: 

* you could do the same with text, by comparing images generated from one sentence versus an entire scene 

Kevin: 
* slow tweaks to midjourney, in order to do iterations with in a discussion. 

* unrelated to our other discussion, but this activity also uses a lot of different mechanics, which is quite cool and something we could integrate into other activities, even if this specific activity isn't used again or in the same way. 


