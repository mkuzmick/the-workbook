---
title: 'Learning Lab Workshops with AI: Spring 2024'

---

# Learning Lab Workshops with AI: Spring 2024
## SLAVIC 121/TDM 121K: Ballet, Past and Present

Students in SLAVIC 121 investigate ballet from an array of perspectives: they reflect on the many ways knowledge about ballet is passed from generation to generation; on the ways ballet is represent, whether in texts or drawings or images or videos; and they grapple with the difficulty of making arguments about a complex and multimodal art form in academic writing.

In their time at the Learning Lab, students engaged in a series of activities that made use of the Learning Lab's media studio and new AI tools to tackle the course material in new ways (but in ways completely aligned with course's objectives). 
- At one station, students worked with printed frame-by-frame stills from the ballets they were analyzing, annotating them as they would in a visual essay
- At another, they learned the basic video editing skills required to isolate specific ballet movements, juxtaposing them in a single frame or assembling a series as a montage, or exporting a series of looping gifs
- Finally, students posed on our green screen stage, then used computer vision tools to analyze and isolate the positions of their bodies in order to feed these in to Stable Diffusion, which is the main open-source AI image generation tool. They learned to use the images of their own poses as controllers that could strictly determine key features of the exported image. In a sense, their bodies became the "input devices" that controlled the AI generation in thought provoking ways.

![A student poses on the green screen with her hands up and legs crossed ](https://files.slack.com/files-pri/T0HTW3H0V-F06NYNTQZTJ/screenshot\_2024-03-06\_at\_4.41.19\_\_\_pm.png?pub_secret=c551410bbe)

![A statue of a woman with the hands up and legs crossed](https://files.slack.com/files-pri/T0HTW3H0V-F06QAJW063S/00025-3564191072\_slavic\_tdm\_121.png?pub\_secret=753e5c5ec1)


## ENGLISH 189VG: Video Game Storytelling
The Learning Lab hosted a five hour workshop for 167 students in ENGLISH 189VG Video Game Storytelling, structuring activities around Jesse Schell's Tetrad: aesthetics, mechanics, story, and technology. For example, at the Aesthetics station, Media & Design Fellow Chris Benham (PhD Candidate in Music) led students through an activity where they built basic environments out of 3d shapes in Blender, and then used Stable Diffusion to give detail, texture, and color, allowing students to create images of their own video game worlds.  AI was also leveraged for character design and narrative construction at the Story station.

![3d modeled shapes, including cylinders, columns, and cubes in grayscale](https://files.slack.com/files-pri/T0HTW3H0V-F06PSDFGFC2/render\_green.local\_20240221\_112926.png?pub\_secret=320389bf2f)

![Fantastical and mysterious video game scene with buildings the shapes of cylinders, columns, and cubes](https://files.slack.com/files-pri/T0HTW3H0V-F06PUT1UW20/00032-3986639472.png?pub_secret=974871e6c2)



## EMR 162: Interdisciplinary Perspectives on Race and Artificial Intelligence
In EMR 162, students analyze the relationship between contemporary discourses about and applications of AI, with an emphasis on the entanglement between artificial intelligence and issues related to race and ethnicity. At the EMR 162 workshop, students explored a range of image and text-generation tools across different platforms as a way to get first-hand experience working with these tools and to experience how they represent race, gender, ethnicity, and class (and the intersections between these identity categories). Students brought prompts with them to the workshop that they used to critically interrogate the output of these different tools. Students reflected on the gap between their "ideal" output (i.e., what they were hoping to get an image or a description of) and what the generative AI tool actually produced. They also experimented with a recursive loop in a low-code environment: here, students would input an initial text prompt and get returned to them the revised prompt that OpenAI uses to tell the LLM specifically what to make. Then, the students would also get a description of that image from Vision API, enabling them to reflect on what the AI "sees" as salient features of an image that it produced itself. Finally, students could then use the image created in the first part of this exercise to get Dall-E to produce the opposite image and then the opposite of that image and so on--this practice allowed the students to grapple with the AI's choices about thematic significance, composition, and identity. At the end of the workshop, students shared some of the images and text that they generated and reflected in a seminar-style discussion about the implications of these different AI-generated outputs and what these modes of representation might mean at both social and political levels.


## COMPLIT 200: Computing Fantasy: Imagination, Invention, Radical Pedagogy (Munari / Rodari / Calvino)

Students in COMPLIT 200 will be coming in to the Learning Lab for sessions in April where theyâ€™ll make use of our resources for their collaborative final project (a book of illustrated AI folktales).
